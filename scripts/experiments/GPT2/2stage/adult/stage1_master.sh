STAGE=1

LEARNING_RATE=0.0005
LR_SCHEDULER_TYPE=linear

IDENTIFIER=adult
BASEFOLDER="${PROJECT_FOLDER}/runs/2Stage_LR${LEARNING_RATE}-k${SEED}-${LR_SCHEDULER_TYPE}/stage1_shuffle-${SHUFFLE_DATASET}-${IDENTIFIER}_wl${WEIGHTED_LOSS}"
TRAIN_SIZE=`cat ${TRAIN_FILE} | wc -l`
MAX_FINETUNE_TRAIN_SIZE=$(($TRAIN_SIZE-1))

# FINETUNE_EPOCH=2
# SAVE_EVERY_EPOCH=1

CHECKPOINT_PATH_2STAGE=None
SAMPLE_BATCH_SIZE=100
N_SYNTH_SAMPLES=${MAX_FINETUNE_TRAIN_SIZE}


if [[ ${STAGE} == '2' ]]
    then
    ENABLE_PRIVACY=True
    SETTING="DP/${LLM}"
else
    ENABLE_PRIVACY=False
    SETTING="NonDP/${LLM}"
fi

FINETUNE_ADAPTER="entire"
CHECKPOINT_EPOCH=$FINETUNE_EPOCH

#  Generation
OUTPUT_DIR=${BASEFOLDER}/${DATASET_NAME}/${SETTING}/${FINETUNE_ADAPTER}/ts${MAX_FINETUNE_TRAIN_SIZE}-bs${TRAIN_BATCH_SIZE}-epoch${FINETUNE_EPOCH}/epoch${CHECKPOINT_EPOCH}
CHECKPOINT_PATH=$OUTPUT_DIR/model.safetensors
SYNTH_FOLDER=$OUTPUT_DIR/synth_data_cat_temp${TEMPERATURE}_top${TOP_P}/
