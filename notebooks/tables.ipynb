{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results/tabular_metrics_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.score=df.apply(lambda x: x.score * 100 if x.metric in [\"efficacy_test\", \"histogram_intersection\"] else x.score, axis=1)\n",
    "df=df.query(\"fake_size == 30932 or fake_size==103904 or fake_size==16858  or fake_size==1000 or fake_size==60127\")\n",
    "df[[\"dataset\", \"setting\", \"llm\", \"finetune_type\"]] = df.apply(lambda x: get_dslf(x), axis=1, result_type=\"expand\")\n",
    "df[\"unique_name\"] = df.apply(lambda x: \"_\".join(x['fake_path'].split(\"/\")[1:-2]),axis=1)\n",
    "\n",
    "\n",
    "df['bs']=df.fake_path.apply(lambda x: get_bs(x))\n",
    "df['exp']=df.fake_path.apply(lambda x: get_exp(x))\n",
    "df['folder_name']=df.fake_path.apply(lambda x: get_folder_name(x))\n",
    "df['train_epoch']=df.fake_path.apply(lambda x: get_train_ep(x))\n",
    "\n",
    "df['chkt_epoch'] = df.fake_path.apply(lambda x: get_epoch(x))\n",
    "df['eps'] = df.fake_path.apply(lambda x: get_eps(x))\n",
    "df['clip']=df.fake_path.apply(lambda x: get_clip(x))\n",
    "df=df.fillna(\"None\")\n",
    "\n",
    "df[\"merged_metric_name\"]=df.apply(lambda x: merge_metric_name(x), axis=1)\n",
    "df[\"merged_metric_name2\"]=df.apply(lambda x: merge_metric_name2(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[\"exp\", \"dataset\", \"llm\", \"finetune_type\", \"folder_name\", \"bs\", \"train_epoch\", \"chkt_epoch\",\"eps\", \"clip\",'fake_size']\n",
    "\n",
    "df['LR']=df.exp.apply(lambda x: x.split(\"-\")[0].strip(\"LR\") if \"LR\" in x else -1)\n",
    "df['shuffle']=df.exp.apply(lambda x: x.split(\"_\")[3].split(\"-\")[-1] if \"shuffle\" in x else \"-1\")\n",
    "df['wl']=df.exp.apply(lambda x: x.split(\"_\")[-1].strip(\"wl\") if \"wl\" in x else \"-1\")\n",
    "df['impute']=df.folder_name.apply(lambda x: x.split(\"_\")[-1].split(\"-\")[-1] if \"impute\" in x else -1)\n",
    "index=index+[\"LR\", \"shuffle\", \"impute\", \"wl\"]\n",
    "\n",
    "def f(x):\n",
    "    \n",
    "    if \"ood-using-airline\" in x:\n",
    "        # print(x)\n",
    "        return \"ood-using-airline\"\n",
    "    elif \"ood-using-adult\" in x:\n",
    "        return \"ood-using-adult\"\n",
    "    elif \"ood-using-texas\" in x:\n",
    "        return \"ood-using-texas\"\n",
    "    elif \"uniform\" in x:\n",
    "        \n",
    "        return \"uniform\"\n",
    "    elif \"Standard\" in x:\n",
    "        return \"standard\"\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "df['approach']=df.exp.apply(lambda x: f(x))\n",
    "index=index+[\"approach\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/cs_w84312s1cxj7105940jzm0000gn/T/ipykernel_56685/1377558198.py:21: FutureWarning: Dropping invalid columns in DataFrameGroupBy.agg is deprecated. In a future version, a TypeError will be raised. Before calling .agg, select only columns which should be valid for the function.\n",
      "  df_tmpp = df_tmp.groupby(index+columns).agg(lambda x:\"$\\pm$\".join([str(x.mean().round(ROUND)), str(x.std().round(ROUND-1))]))[[\"score\"]].reset_index().pivot(columns=columns, index=index, values=\"score\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merged_metric_name2</th>\n",
       "      <th>efficacy_f1</th>\n",
       "      <th>efficacy_auc</th>\n",
       "      <th>efficacy_accuracy</th>\n",
       "      <th>correlation_accuracy</th>\n",
       "      <th>pairwise_mean</th>\n",
       "      <th>histogram_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">adult</th>\n",
       "      <th>real</th>\n",
       "      <td>69.9$\\pm$2.0</td>\n",
       "      <td>91.7$\\pm$1.0</td>\n",
       "      <td>84.0$\\pm$4.0</td>\n",
       "      <td>97.3$\\pm$nan</td>\n",
       "      <td>97.5$\\pm$0.0</td>\n",
       "      <td>99.1$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctgan</th>\n",
       "      <td>59.5$\\pm$6.0</td>\n",
       "      <td>88.5$\\pm$0.0</td>\n",
       "      <td>80.2$\\pm$3.0</td>\n",
       "      <td>74.9$\\pm$4.0</td>\n",
       "      <td>85.0$\\pm$1.0</td>\n",
       "      <td>91.2$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tvae</th>\n",
       "      <td>63.2$\\pm$2.0</td>\n",
       "      <td>87.5$\\pm$1.0</td>\n",
       "      <td>77.7$\\pm$4.0</td>\n",
       "      <td>76.6$\\pm$2.0</td>\n",
       "      <td>84.5$\\pm$1.0</td>\n",
       "      <td>91.5$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vae</th>\n",
       "      <td>53.8$\\pm$10.0</td>\n",
       "      <td>86.6$\\pm$1.0</td>\n",
       "      <td>80.5$\\pm$1.0</td>\n",
       "      <td>65.3$\\pm$2.0</td>\n",
       "      <td>60.2$\\pm$2.0</td>\n",
       "      <td>73.3$\\pm$3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT2</th>\n",
       "      <td>68.9$\\pm$0.0</td>\n",
       "      <td>90.7$\\pm$0.0</td>\n",
       "      <td>83.7$\\pm$2.0</td>\n",
       "      <td>79.9$\\pm$1.0</td>\n",
       "      <td>83.7$\\pm$0.0</td>\n",
       "      <td>90.7$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">airline</th>\n",
       "      <th>real</th>\n",
       "      <td>90.6$\\pm$8.0</td>\n",
       "      <td>96.2$\\pm$5.0</td>\n",
       "      <td>91.8$\\pm$7.0</td>\n",
       "      <td>97.2$\\pm$nan</td>\n",
       "      <td>98.4$\\pm$0.0</td>\n",
       "      <td>99.4$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctgan</th>\n",
       "      <td>87.2$\\pm$3.0</td>\n",
       "      <td>94.7$\\pm$2.0</td>\n",
       "      <td>88.9$\\pm$3.0</td>\n",
       "      <td>84.4$\\pm$1.0</td>\n",
       "      <td>89.3$\\pm$1.0</td>\n",
       "      <td>94.4$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tvae</th>\n",
       "      <td>85.8$\\pm$5.0</td>\n",
       "      <td>93.0$\\pm$6.0</td>\n",
       "      <td>87.2$\\pm$6.0</td>\n",
       "      <td>78.0$\\pm$3.0</td>\n",
       "      <td>82.8$\\pm$3.0</td>\n",
       "      <td>90.3$\\pm$2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vae</th>\n",
       "      <td>79.8$\\pm$1.0</td>\n",
       "      <td>91.1$\\pm$1.0</td>\n",
       "      <td>80.0$\\pm$1.0</td>\n",
       "      <td>67.8$\\pm$5.0</td>\n",
       "      <td>60.4$\\pm$1.0</td>\n",
       "      <td>76.8$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT2</th>\n",
       "      <td>89.6$\\pm$5.0</td>\n",
       "      <td>95.9$\\pm$3.0</td>\n",
       "      <td>91.4$\\pm$4.0</td>\n",
       "      <td>86.5$\\pm$4.0</td>\n",
       "      <td>85.5$\\pm$2.0</td>\n",
       "      <td>90.8$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">texas</th>\n",
       "      <th>real</th>\n",
       "      <td>86.6$\\pm$2.0</td>\n",
       "      <td>98.8$\\pm$0.0</td>\n",
       "      <td>95.0$\\pm$1.0</td>\n",
       "      <td>96.3$\\pm$nan</td>\n",
       "      <td>98.9$\\pm$0.0</td>\n",
       "      <td>99.5$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctgan</th>\n",
       "      <td>80.8$\\pm$4.0</td>\n",
       "      <td>96.8$\\pm$2.0</td>\n",
       "      <td>92.8$\\pm$2.0</td>\n",
       "      <td>72.8$\\pm$4.0</td>\n",
       "      <td>88.3$\\pm$1.0</td>\n",
       "      <td>93.1$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tvae</th>\n",
       "      <td>76.7$\\pm$7.0</td>\n",
       "      <td>95.3$\\pm$3.0</td>\n",
       "      <td>90.9$\\pm$3.0</td>\n",
       "      <td>61.2$\\pm$4.0</td>\n",
       "      <td>63.4$\\pm$7.0</td>\n",
       "      <td>93.5$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vae</th>\n",
       "      <td>74.3$\\pm$3.0</td>\n",
       "      <td>95.6$\\pm$1.0</td>\n",
       "      <td>90.6$\\pm$2.0</td>\n",
       "      <td>51.5$\\pm$7.0</td>\n",
       "      <td>57.5$\\pm$1.0</td>\n",
       "      <td>89.3$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT2</th>\n",
       "      <td>83.9$\\pm$2.0</td>\n",
       "      <td>98.6$\\pm$0.0</td>\n",
       "      <td>93.6$\\pm$1.0</td>\n",
       "      <td>72.8$\\pm$1.0</td>\n",
       "      <td>82.8$\\pm$3.0</td>\n",
       "      <td>94.9$\\pm$0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "merged_metric_name2    efficacy_f1  efficacy_auc efficacy_accuracy  \\\n",
       "dataset llm                                                          \n",
       "adult   real          69.9$\\pm$2.0  91.7$\\pm$1.0      84.0$\\pm$4.0   \n",
       "        ctgan         59.5$\\pm$6.0  88.5$\\pm$0.0      80.2$\\pm$3.0   \n",
       "        tvae          63.2$\\pm$2.0  87.5$\\pm$1.0      77.7$\\pm$4.0   \n",
       "        vae          53.8$\\pm$10.0  86.6$\\pm$1.0      80.5$\\pm$1.0   \n",
       "        GPT2          68.9$\\pm$0.0  90.7$\\pm$0.0      83.7$\\pm$2.0   \n",
       "airline real          90.6$\\pm$8.0  96.2$\\pm$5.0      91.8$\\pm$7.0   \n",
       "        ctgan         87.2$\\pm$3.0  94.7$\\pm$2.0      88.9$\\pm$3.0   \n",
       "        tvae          85.8$\\pm$5.0  93.0$\\pm$6.0      87.2$\\pm$6.0   \n",
       "        vae           79.8$\\pm$1.0  91.1$\\pm$1.0      80.0$\\pm$1.0   \n",
       "        GPT2          89.6$\\pm$5.0  95.9$\\pm$3.0      91.4$\\pm$4.0   \n",
       "texas   real          86.6$\\pm$2.0  98.8$\\pm$0.0      95.0$\\pm$1.0   \n",
       "        ctgan         80.8$\\pm$4.0  96.8$\\pm$2.0      92.8$\\pm$2.0   \n",
       "        tvae          76.7$\\pm$7.0  95.3$\\pm$3.0      90.9$\\pm$3.0   \n",
       "        vae           74.3$\\pm$3.0  95.6$\\pm$1.0      90.6$\\pm$2.0   \n",
       "        GPT2          83.9$\\pm$2.0  98.6$\\pm$0.0      93.6$\\pm$1.0   \n",
       "\n",
       "merged_metric_name2 correlation_accuracy pairwise_mean histogram_mean  \n",
       "dataset llm                                                            \n",
       "adult   real                97.3$\\pm$nan  97.5$\\pm$0.0   99.1$\\pm$0.0  \n",
       "        ctgan               74.9$\\pm$4.0  85.0$\\pm$1.0   91.2$\\pm$1.0  \n",
       "        tvae                76.6$\\pm$2.0  84.5$\\pm$1.0   91.5$\\pm$1.0  \n",
       "        vae                 65.3$\\pm$2.0  60.2$\\pm$2.0   73.3$\\pm$3.0  \n",
       "        GPT2                79.9$\\pm$1.0  83.7$\\pm$0.0   90.7$\\pm$1.0  \n",
       "airline real                97.2$\\pm$nan  98.4$\\pm$0.0   99.4$\\pm$0.0  \n",
       "        ctgan               84.4$\\pm$1.0  89.3$\\pm$1.0   94.4$\\pm$1.0  \n",
       "        tvae                78.0$\\pm$3.0  82.8$\\pm$3.0   90.3$\\pm$2.0  \n",
       "        vae                 67.8$\\pm$5.0  60.4$\\pm$1.0   76.8$\\pm$0.0  \n",
       "        GPT2                86.5$\\pm$4.0  85.5$\\pm$2.0   90.8$\\pm$1.0  \n",
       "texas   real                96.3$\\pm$nan  98.9$\\pm$0.0   99.5$\\pm$0.0  \n",
       "        ctgan               72.8$\\pm$4.0  88.3$\\pm$1.0   93.1$\\pm$0.0  \n",
       "        tvae                61.2$\\pm$4.0  63.4$\\pm$7.0   93.5$\\pm$1.0  \n",
       "        vae                 51.5$\\pm$7.0  57.5$\\pm$1.0   89.3$\\pm$1.0  \n",
       "        GPT2                72.8$\\pm$1.0  82.8$\\pm$3.0   94.9$\\pm$0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps=1\n",
    "query1=f\"llm in ('ctgan', 'tvae', 'vae') and dataset in ('adult', 'airline', 'texas')\"\n",
    "query2=f\"llm=='GPT2' and dataset in ('adult', 'airline', 'texas') and LR=='0.0005' and shuffle == 'True' and impute=='False' and eps=='nondp'\"\n",
    "query3=f\"llm=='real' and dataset in ('adult', 'airline', 'texas')\"\n",
    "\n",
    "\n",
    "index=[\"dataset\", \"llm\", \"finetune_type\", \"folder_name\", \"bs\", \"train_epoch\", \"chkt_epoch\",\"eps\", \"clip\",'fake_size']\n",
    "index=index+[\"LR\", \"shuffle\", \"impute\", \"wl\"]\n",
    "index=index+[\"approach\"]\n",
    "df_tmp=df.query(f\"{query1} or {query2} or {query3}\")\n",
    "df_tmp=df_tmp[df_tmp['exp'] != 'baselines_adult']\n",
    "df_tmp=df_tmp[df_tmp['exp'] != 'baseline-test_airline']\n",
    "df_tmp = df_tmp[df_tmp.fake_path.apply(lambda x: 'baselines' not in x)]\n",
    "df_tmp['score']=df_tmp.apply(lambda x: x['score'] * 100 if x['metric'] == 'correlation_accuracy' or x['metric'] == 'pairwise_similarity' else x['score'], axis=1)\n",
    "\n",
    "columns=[\"merged_metric_name2\"]\n",
    "tabular_metrics=['efficacy_f1', 'efficacy_auc', 'efficacy_accuracy', 'correlation_accuracy', 'pairwise_mean', 'histogram_mean']\n",
    "# assert len(df_tmp.fake_path.unique()) == (6*2*4) + (5*1*4)\n",
    "\n",
    "ROUND=1\n",
    "df_tmpp = df_tmp.groupby(index+columns).agg(lambda x:\"$\\pm$\".join([str(x.mean().round(ROUND)), str(x.std().round(ROUND-1))]))[[\"score\"]].reset_index().pivot(columns=columns, index=index, values=\"score\")\n",
    "df_tmpp = df_tmpp[~df_tmpp.efficacy_f1.isna()]\n",
    "df_tmpp=df_tmpp.reset_index().set_index(['dataset', 'llm'])[tabular_metrics].loc[['adult', 'airline', 'texas'], ['real', 'ctgan', 'tvae', 'vae', 'GPT2'], :]\n",
    "\n",
    "df_tmpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 3 and Appendix F.2, Table 8\n",
    "\n",
    "The correlation Accuracy score for DP-2Stage-U, texas dataset doesn't exactly match the paper. Table below shows that it performs better than what was reported.  Paper reports $80.7\\pm6$ but the table below shows $81.2\\pm6$. I might have made a mistake when copying over the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/cs_w84312s1cxj7105940jzm0000gn/T/ipykernel_56685/1655157872.py:22: FutureWarning: Dropping invalid columns in DataFrameGroupBy.agg is deprecated. In a future version, a TypeError will be raised. Before calling .agg, select only columns which should be valid for the function.\n",
      "  df_tmpp = df_tmp.groupby(index+columns).agg(lambda x:\"$\\pm$\".join([str(x.mean().round(ROUND)), str(x.std().round(ROUND-1))]))[[\"score\"]].reset_index().pivot(columns=columns, index=index, values=\"score\").fillna(\"-\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>merged_metric_name2</th>\n",
       "      <th>efficacy_f1</th>\n",
       "      <th>efficacy_auc</th>\n",
       "      <th>efficacy_accuracy</th>\n",
       "      <th>correlation_accuracy</th>\n",
       "      <th>pairwise_mean</th>\n",
       "      <th>histogram_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>llm</th>\n",
       "      <th>approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">adult</th>\n",
       "      <th>aim</th>\n",
       "      <th>-1</th>\n",
       "      <td>59.6$\\pm$6.0</td>\n",
       "      <td>86.8$\\pm$1.0</td>\n",
       "      <td>80.3$\\pm$2.0</td>\n",
       "      <td>86.4$\\pm$1.0</td>\n",
       "      <td>77.1$\\pm$9.0</td>\n",
       "      <td>88.4$\\pm$5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mst</th>\n",
       "      <th>-1</th>\n",
       "      <td>39.6$\\pm$19.0</td>\n",
       "      <td>76.8$\\pm$1.0</td>\n",
       "      <td>72.8$\\pm$2.0</td>\n",
       "      <td>70.0$\\pm$1.0</td>\n",
       "      <td>74.6$\\pm$10.0</td>\n",
       "      <td>87.0$\\pm$5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpgan</th>\n",
       "      <th>-1</th>\n",
       "      <td>33.5$\\pm$20.0</td>\n",
       "      <td>67.7$\\pm$9.0</td>\n",
       "      <td>64.2$\\pm$10.0</td>\n",
       "      <td>39.9$\\pm$3.0</td>\n",
       "      <td>41.2$\\pm$4.0</td>\n",
       "      <td>63.7$\\pm$3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpctgan</th>\n",
       "      <th>-1</th>\n",
       "      <td>42.2$\\pm$20.0</td>\n",
       "      <td>78.0$\\pm$7.0</td>\n",
       "      <td>75.7$\\pm$3.0</td>\n",
       "      <td>51.3$\\pm$3.0</td>\n",
       "      <td>59.2$\\pm$2.0</td>\n",
       "      <td>75.7$\\pm$2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpvae</th>\n",
       "      <th>-1</th>\n",
       "      <td>0.0$\\pm$0.0</td>\n",
       "      <td>50.0$\\pm$0.0</td>\n",
       "      <td>75.6$\\pm$0.0</td>\n",
       "      <td>48.8$\\pm$1.0</td>\n",
       "      <td>40.3$\\pm$1.0</td>\n",
       "      <td>61.8$\\pm$2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">GPT2</th>\n",
       "      <th>standard</th>\n",
       "      <td>27.8$\\pm$15.0</td>\n",
       "      <td>58.5$\\pm$7.0</td>\n",
       "      <td>65.2$\\pm$9.0</td>\n",
       "      <td>55.0$\\pm$1.0</td>\n",
       "      <td>68.4$\\pm$1.0</td>\n",
       "      <td>85.7$\\pm$2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>21.2$\\pm$12.0</td>\n",
       "      <td>48.9$\\pm$6.0</td>\n",
       "      <td>61.9$\\pm$13.0</td>\n",
       "      <td>55.0$\\pm$1.0</td>\n",
       "      <td>76.1$\\pm$1.0</td>\n",
       "      <td>86.7$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ood-using-airline</th>\n",
       "      <td>30.4$\\pm$17.0</td>\n",
       "      <td>61.6$\\pm$8.0</td>\n",
       "      <td>66.7$\\pm$8.0</td>\n",
       "      <td>55.4$\\pm$1.0</td>\n",
       "      <td>72.3$\\pm$1.0</td>\n",
       "      <td>88.5$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ood-using-texas</th>\n",
       "      <td>31.6$\\pm$13.0</td>\n",
       "      <td>60.5$\\pm$7.0</td>\n",
       "      <td>66.4$\\pm$8.0</td>\n",
       "      <td>55.6$\\pm$1.0</td>\n",
       "      <td>71.3$\\pm$1.0</td>\n",
       "      <td>86.9$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">airline</th>\n",
       "      <th>aim</th>\n",
       "      <th>-1</th>\n",
       "      <td>77.3$\\pm$5.0</td>\n",
       "      <td>88.9$\\pm$4.0</td>\n",
       "      <td>78.2$\\pm$5.0</td>\n",
       "      <td>91.8$\\pm$1.0</td>\n",
       "      <td>46.7$\\pm$3.0</td>\n",
       "      <td>68.1$\\pm$2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mst</th>\n",
       "      <th>-1</th>\n",
       "      <td>72.2$\\pm$6.0</td>\n",
       "      <td>83.4$\\pm$5.0</td>\n",
       "      <td>75.2$\\pm$4.0</td>\n",
       "      <td>72.7$\\pm$0.0</td>\n",
       "      <td>46.3$\\pm$3.0</td>\n",
       "      <td>68.2$\\pm$2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpgan</th>\n",
       "      <th>-1</th>\n",
       "      <td>40.2$\\pm$24.0</td>\n",
       "      <td>63.9$\\pm$13.0</td>\n",
       "      <td>59.8$\\pm$6.0</td>\n",
       "      <td>37.4$\\pm$9.0</td>\n",
       "      <td>22.2$\\pm$13.0</td>\n",
       "      <td>44.7$\\pm$12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpctgan</th>\n",
       "      <th>-1</th>\n",
       "      <td>67.1$\\pm$8.0</td>\n",
       "      <td>76.7$\\pm$8.0</td>\n",
       "      <td>68.0$\\pm$6.0</td>\n",
       "      <td>31.7$\\pm$2.0</td>\n",
       "      <td>62.2$\\pm$2.0</td>\n",
       "      <td>78.7$\\pm$2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpvae</th>\n",
       "      <th>-1</th>\n",
       "      <td>26.5$\\pm$28.0</td>\n",
       "      <td>57.9$\\pm$13.0</td>\n",
       "      <td>57.3$\\pm$6.0</td>\n",
       "      <td>46.6$\\pm$1.0</td>\n",
       "      <td>20.6$\\pm$0.0</td>\n",
       "      <td>41.8$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">GPT2</th>\n",
       "      <th>standard</th>\n",
       "      <td>60.5$\\pm$7.0</td>\n",
       "      <td>65.3$\\pm$9.0</td>\n",
       "      <td>62.4$\\pm$7.0</td>\n",
       "      <td>64.0$\\pm$2.0</td>\n",
       "      <td>77.0$\\pm$2.0</td>\n",
       "      <td>90.3$\\pm$3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>68.5$\\pm$9.0</td>\n",
       "      <td>77.8$\\pm$10.0</td>\n",
       "      <td>72.1$\\pm$7.0</td>\n",
       "      <td>65.3$\\pm$1.0</td>\n",
       "      <td>80.8$\\pm$1.0</td>\n",
       "      <td>90.7$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ood-using-adult</th>\n",
       "      <td>55.2$\\pm$18.0</td>\n",
       "      <td>62.5$\\pm$19.0</td>\n",
       "      <td>60.0$\\pm$16.0</td>\n",
       "      <td>66.8$\\pm$1.0</td>\n",
       "      <td>80.1$\\pm$1.0</td>\n",
       "      <td>92.5$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ood-using-texas</th>\n",
       "      <td>52.5$\\pm$13.0</td>\n",
       "      <td>61.0$\\pm$13.0</td>\n",
       "      <td>58.4$\\pm$10.0</td>\n",
       "      <td>66.1$\\pm$2.0</td>\n",
       "      <td>78.7$\\pm$2.0</td>\n",
       "      <td>90.4$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">texas</th>\n",
       "      <th>aim</th>\n",
       "      <th>-1</th>\n",
       "      <td>84.5$\\pm$1.0</td>\n",
       "      <td>98.3$\\pm$0.0</td>\n",
       "      <td>94.2$\\pm$1.0</td>\n",
       "      <td>81.0$\\pm$2.0</td>\n",
       "      <td>93.0$\\pm$5.0</td>\n",
       "      <td>98.9$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mst</th>\n",
       "      <th>-1</th>\n",
       "      <td>81.7$\\pm$0.0</td>\n",
       "      <td>94.8$\\pm$0.0</td>\n",
       "      <td>93.2$\\pm$0.0</td>\n",
       "      <td>77.0$\\pm$0.0</td>\n",
       "      <td>97.5$\\pm$0.0</td>\n",
       "      <td>99.0$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpgan</th>\n",
       "      <th>-1</th>\n",
       "      <td>13.7$\\pm$16.0</td>\n",
       "      <td>58.3$\\pm$12.0</td>\n",
       "      <td>78.3$\\pm$8.0</td>\n",
       "      <td>36.1$\\pm$7.0</td>\n",
       "      <td>34.6$\\pm$5.0</td>\n",
       "      <td>68.3$\\pm$7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpctgan</th>\n",
       "      <th>-1</th>\n",
       "      <td>63.9$\\pm$11.0</td>\n",
       "      <td>91.4$\\pm$3.0</td>\n",
       "      <td>82.6$\\pm$19.0</td>\n",
       "      <td>43.9$\\pm$6.0</td>\n",
       "      <td>66.9$\\pm$6.0</td>\n",
       "      <td>84.7$\\pm$3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpvae</th>\n",
       "      <th>-1</th>\n",
       "      <td>0.0$\\pm$0.0</td>\n",
       "      <td>50.0$\\pm$0.0</td>\n",
       "      <td>82.5$\\pm$0.0</td>\n",
       "      <td>62.1$\\pm$1.0</td>\n",
       "      <td>43.9$\\pm$1.0</td>\n",
       "      <td>77.9$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">GPT2</th>\n",
       "      <th>standard</th>\n",
       "      <td>55.4$\\pm$10.0</td>\n",
       "      <td>90.2$\\pm$5.0</td>\n",
       "      <td>77.1$\\pm$11.0</td>\n",
       "      <td>70.3$\\pm$1.0</td>\n",
       "      <td>60.6$\\pm$1.0</td>\n",
       "      <td>92.3$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>23.5$\\pm$15.0</td>\n",
       "      <td>59.6$\\pm$15.0</td>\n",
       "      <td>67.3$\\pm$17.0</td>\n",
       "      <td>68.2$\\pm$0.0</td>\n",
       "      <td>81.2$\\pm$6.0</td>\n",
       "      <td>93.4$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ood-using-adult</th>\n",
       "      <td>74.8$\\pm$4.0</td>\n",
       "      <td>96.7$\\pm$1.0</td>\n",
       "      <td>89.1$\\pm$3.0</td>\n",
       "      <td>69.9$\\pm$2.0</td>\n",
       "      <td>60.5$\\pm$2.0</td>\n",
       "      <td>91.7$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ood-using-airline</th>\n",
       "      <td>74.3$\\pm$5.0</td>\n",
       "      <td>96.4$\\pm$0.0</td>\n",
       "      <td>88.8$\\pm$3.0</td>\n",
       "      <td>70.9$\\pm$1.0</td>\n",
       "      <td>62.0$\\pm$2.0</td>\n",
       "      <td>93.2$\\pm$0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "merged_metric_name2                  efficacy_f1   efficacy_auc  \\\n",
       "dataset llm     approach                                          \n",
       "adult   aim     -1                  59.6$\\pm$6.0   86.8$\\pm$1.0   \n",
       "        mst     -1                 39.6$\\pm$19.0   76.8$\\pm$1.0   \n",
       "        dpgan   -1                 33.5$\\pm$20.0   67.7$\\pm$9.0   \n",
       "        dpctgan -1                 42.2$\\pm$20.0   78.0$\\pm$7.0   \n",
       "        dpvae   -1                   0.0$\\pm$0.0   50.0$\\pm$0.0   \n",
       "        GPT2    standard           27.8$\\pm$15.0   58.5$\\pm$7.0   \n",
       "                uniform            21.2$\\pm$12.0   48.9$\\pm$6.0   \n",
       "                ood-using-airline  30.4$\\pm$17.0   61.6$\\pm$8.0   \n",
       "                ood-using-texas    31.6$\\pm$13.0   60.5$\\pm$7.0   \n",
       "airline aim     -1                  77.3$\\pm$5.0   88.9$\\pm$4.0   \n",
       "        mst     -1                  72.2$\\pm$6.0   83.4$\\pm$5.0   \n",
       "        dpgan   -1                 40.2$\\pm$24.0  63.9$\\pm$13.0   \n",
       "        dpctgan -1                  67.1$\\pm$8.0   76.7$\\pm$8.0   \n",
       "        dpvae   -1                 26.5$\\pm$28.0  57.9$\\pm$13.0   \n",
       "        GPT2    standard            60.5$\\pm$7.0   65.3$\\pm$9.0   \n",
       "                uniform             68.5$\\pm$9.0  77.8$\\pm$10.0   \n",
       "                ood-using-adult    55.2$\\pm$18.0  62.5$\\pm$19.0   \n",
       "                ood-using-texas    52.5$\\pm$13.0  61.0$\\pm$13.0   \n",
       "texas   aim     -1                  84.5$\\pm$1.0   98.3$\\pm$0.0   \n",
       "        mst     -1                  81.7$\\pm$0.0   94.8$\\pm$0.0   \n",
       "        dpgan   -1                 13.7$\\pm$16.0  58.3$\\pm$12.0   \n",
       "        dpctgan -1                 63.9$\\pm$11.0   91.4$\\pm$3.0   \n",
       "        dpvae   -1                   0.0$\\pm$0.0   50.0$\\pm$0.0   \n",
       "        GPT2    standard           55.4$\\pm$10.0   90.2$\\pm$5.0   \n",
       "                uniform            23.5$\\pm$15.0  59.6$\\pm$15.0   \n",
       "                ood-using-adult     74.8$\\pm$4.0   96.7$\\pm$1.0   \n",
       "                ood-using-airline   74.3$\\pm$5.0   96.4$\\pm$0.0   \n",
       "\n",
       "merged_metric_name2               efficacy_accuracy correlation_accuracy  \\\n",
       "dataset llm     approach                                                   \n",
       "adult   aim     -1                     80.3$\\pm$2.0         86.4$\\pm$1.0   \n",
       "        mst     -1                     72.8$\\pm$2.0         70.0$\\pm$1.0   \n",
       "        dpgan   -1                    64.2$\\pm$10.0         39.9$\\pm$3.0   \n",
       "        dpctgan -1                     75.7$\\pm$3.0         51.3$\\pm$3.0   \n",
       "        dpvae   -1                     75.6$\\pm$0.0         48.8$\\pm$1.0   \n",
       "        GPT2    standard               65.2$\\pm$9.0         55.0$\\pm$1.0   \n",
       "                uniform               61.9$\\pm$13.0         55.0$\\pm$1.0   \n",
       "                ood-using-airline      66.7$\\pm$8.0         55.4$\\pm$1.0   \n",
       "                ood-using-texas        66.4$\\pm$8.0         55.6$\\pm$1.0   \n",
       "airline aim     -1                     78.2$\\pm$5.0         91.8$\\pm$1.0   \n",
       "        mst     -1                     75.2$\\pm$4.0         72.7$\\pm$0.0   \n",
       "        dpgan   -1                     59.8$\\pm$6.0         37.4$\\pm$9.0   \n",
       "        dpctgan -1                     68.0$\\pm$6.0         31.7$\\pm$2.0   \n",
       "        dpvae   -1                     57.3$\\pm$6.0         46.6$\\pm$1.0   \n",
       "        GPT2    standard               62.4$\\pm$7.0         64.0$\\pm$2.0   \n",
       "                uniform                72.1$\\pm$7.0         65.3$\\pm$1.0   \n",
       "                ood-using-adult       60.0$\\pm$16.0         66.8$\\pm$1.0   \n",
       "                ood-using-texas       58.4$\\pm$10.0         66.1$\\pm$2.0   \n",
       "texas   aim     -1                     94.2$\\pm$1.0         81.0$\\pm$2.0   \n",
       "        mst     -1                     93.2$\\pm$0.0         77.0$\\pm$0.0   \n",
       "        dpgan   -1                     78.3$\\pm$8.0         36.1$\\pm$7.0   \n",
       "        dpctgan -1                    82.6$\\pm$19.0         43.9$\\pm$6.0   \n",
       "        dpvae   -1                     82.5$\\pm$0.0         62.1$\\pm$1.0   \n",
       "        GPT2    standard              77.1$\\pm$11.0         70.3$\\pm$1.0   \n",
       "                uniform               67.3$\\pm$17.0         68.2$\\pm$0.0   \n",
       "                ood-using-adult        89.1$\\pm$3.0         69.9$\\pm$2.0   \n",
       "                ood-using-airline      88.8$\\pm$3.0         70.9$\\pm$1.0   \n",
       "\n",
       "merged_metric_name2                pairwise_mean histogram_mean  \n",
       "dataset llm     approach                                         \n",
       "adult   aim     -1                  77.1$\\pm$9.0   88.4$\\pm$5.0  \n",
       "        mst     -1                 74.6$\\pm$10.0   87.0$\\pm$5.0  \n",
       "        dpgan   -1                  41.2$\\pm$4.0   63.7$\\pm$3.0  \n",
       "        dpctgan -1                  59.2$\\pm$2.0   75.7$\\pm$2.0  \n",
       "        dpvae   -1                  40.3$\\pm$1.0   61.8$\\pm$2.0  \n",
       "        GPT2    standard            68.4$\\pm$1.0   85.7$\\pm$2.0  \n",
       "                uniform             76.1$\\pm$1.0   86.7$\\pm$1.0  \n",
       "                ood-using-airline   72.3$\\pm$1.0   88.5$\\pm$1.0  \n",
       "                ood-using-texas     71.3$\\pm$1.0   86.9$\\pm$1.0  \n",
       "airline aim     -1                  46.7$\\pm$3.0   68.1$\\pm$2.0  \n",
       "        mst     -1                  46.3$\\pm$3.0   68.2$\\pm$2.0  \n",
       "        dpgan   -1                 22.2$\\pm$13.0  44.7$\\pm$12.0  \n",
       "        dpctgan -1                  62.2$\\pm$2.0   78.7$\\pm$2.0  \n",
       "        dpvae   -1                  20.6$\\pm$0.0   41.8$\\pm$1.0  \n",
       "        GPT2    standard            77.0$\\pm$2.0   90.3$\\pm$3.0  \n",
       "                uniform             80.8$\\pm$1.0   90.7$\\pm$1.0  \n",
       "                ood-using-adult     80.1$\\pm$1.0   92.5$\\pm$1.0  \n",
       "                ood-using-texas     78.7$\\pm$2.0   90.4$\\pm$1.0  \n",
       "texas   aim     -1                  93.0$\\pm$5.0   98.9$\\pm$0.0  \n",
       "        mst     -1                  97.5$\\pm$0.0   99.0$\\pm$0.0  \n",
       "        dpgan   -1                  34.6$\\pm$5.0   68.3$\\pm$7.0  \n",
       "        dpctgan -1                  66.9$\\pm$6.0   84.7$\\pm$3.0  \n",
       "        dpvae   -1                  43.9$\\pm$1.0   77.9$\\pm$1.0  \n",
       "        GPT2    standard            60.6$\\pm$1.0   92.3$\\pm$1.0  \n",
       "                uniform             81.2$\\pm$6.0   93.4$\\pm$0.0  \n",
       "                ood-using-adult     60.5$\\pm$2.0   91.7$\\pm$1.0  \n",
       "                ood-using-airline   62.0$\\pm$2.0   93.2$\\pm$0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps=1\n",
    "query1=f\"llm in ('aim', 'mst', 'dpgan', 'dpctgan', 'dpvae') and dataset in('adult', 'airline', 'texas') and eps=={eps}\"\n",
    "query2=f\"llm=='GPT2'and dataset in ('adult', 'airline', 'texas') and LR=='0.0005' and approach == 'standard' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '-1'\"\n",
    "query3=f\"llm=='GPT2' and dataset in ('adult', 'airline', 'texas') and LR=='0.0005' and approach == 'uniform' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '0.65'\"\n",
    "query4=f\"llm=='GPT2' and dataset in ('adult', 'airline', 'texas') and LR=='0.0005' and approach == 'ood-using-adult' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '0.65'\"\n",
    "query5=f\"llm=='GPT2' and dataset in ('adult', 'airline', 'texas') and LR=='0.0005' and approach == 'ood-using-airline' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '0.65'\"\n",
    "query6=f\"llm=='GPT2' and dataset in ('adult', 'airline', 'texas') and LR=='0.0005' and approach == 'ood-using-texas' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '0.65'\"\n",
    "\n",
    "\n",
    "index=[\"dataset\", \"llm\", \"finetune_type\", \"folder_name\", \"bs\", \"train_epoch\", \"chkt_epoch\",\"eps\", \"clip\",'fake_size', \"LR\", \"shuffle\", \"impute\", \"wl\", \"approach\"]\n",
    "df_tmp=df.query(f\"{query1} or {query2} or {query3} or {query4} or {query5} or {query6}\")\n",
    "df_tmp=df_tmp[df_tmp['exp'] != 'baselines_adult']\n",
    "df_tmp=df_tmp[df_tmp['exp'] != 'baseline-test_airline']\n",
    "df_tmp = df_tmp[df_tmp.fake_path.apply(lambda x: 'baselines' not in x)]\n",
    "df_tmp['score']=df_tmp.apply(lambda x: x['score'] * 100 if x['metric'] == 'correlation_accuracy' or x['metric'] == 'pairwise_similarity' else x['score'], axis=1)\n",
    "\n",
    "columns=[\"merged_metric_name2\"]\n",
    "tabular_metrics=['efficacy_f1', 'efficacy_auc', 'efficacy_accuracy', 'correlation_accuracy', 'pairwise_mean', 'histogram_mean']\n",
    "# assert len(df_tmp.fake_path.unique()) == (6*2*4) + (5*1*4)\n",
    "\n",
    "ROUND=1\n",
    "df_tmpp = df_tmp.groupby(index+columns).agg(lambda x:\"$\\pm$\".join([str(x.mean().round(ROUND)), str(x.std().round(ROUND-1))]))[[\"score\"]].reset_index().pivot(columns=columns, index=index, values=\"score\").fillna(\"-\")\n",
    "df_tmpp=df_tmpp.reset_index().set_index(['dataset', 'llm', 'approach'])[tabular_metrics].loc[['adult', 'airline', 'texas'], ['aim', 'mst', 'dpgan', 'dpctgan', 'dpvae', 'GPT2'], [-1, -1, -1, -1, -1, 'standard', 'uniform', \n",
    "                                                                                                                                                                                         'ood-using-adult', \n",
    "                                                                                                                                                                                         'ood-using-airline',\n",
    "                                                                                                                                                                                         'ood-using-texas',]]\n",
    "df_tmpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 4\n",
    "\n",
    "Numbers don't match exactly because the table below is averaged over all the experiments I ran but the reported table in the paper is based on single run (the first run) for DP-Standard and DP-2Stage-O, mostly because some of the experiments when shuffle is True did not run to completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/cs_w84312s1cxj7105940jzm0000gn/T/ipykernel_56685/4142321769.py:26: FutureWarning: Dropping invalid columns in DataFrameGroupBy.agg is deprecated. In a future version, a TypeError will be raised. Before calling .agg, select only columns which should be valid for the function.\n",
      "  df_tmpp = df_tmp.groupby(index+columns).agg(lambda x:\"$\\pm$\".join([str(x.mean().round(ROUND)), str(x.std().round(ROUND-1))]))[[\"score\"]].reset_index().pivot(columns=columns, index=index, values=\"score\").fillna(\"-\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>merged_metric_name2</th>\n",
       "      <th>efficacy_f1</th>\n",
       "      <th>efficacy_auc</th>\n",
       "      <th>efficacy_accuracy</th>\n",
       "      <th>histogram_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>llm</th>\n",
       "      <th>eps</th>\n",
       "      <th>approach</th>\n",
       "      <th>shuffle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">adult</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">GPT2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">nondp</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">standard</th>\n",
       "      <th>True</th>\n",
       "      <td>68.9$\\pm$0.0</td>\n",
       "      <td>90.7$\\pm$0.0</td>\n",
       "      <td>83.7$\\pm$2.0</td>\n",
       "      <td>90.7$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>69.0$\\pm$1.0</td>\n",
       "      <td>90.7$\\pm$0.0</td>\n",
       "      <td>83.3$\\pm$2.0</td>\n",
       "      <td>90.2$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">standard</th>\n",
       "      <th>True</th>\n",
       "      <td>19.5$\\pm$20.0</td>\n",
       "      <td>54.2$\\pm$12.0</td>\n",
       "      <td>64.0$\\pm$13.0</td>\n",
       "      <td>87.7$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>27.8$\\pm$15.0</td>\n",
       "      <td>58.5$\\pm$7.0</td>\n",
       "      <td>65.2$\\pm$9.0</td>\n",
       "      <td>85.7$\\pm$2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uniform</th>\n",
       "      <th>True</th>\n",
       "      <td>19.7$\\pm$13.0</td>\n",
       "      <td>48.0$\\pm$8.0</td>\n",
       "      <td>61.9$\\pm$13.0</td>\n",
       "      <td>87.6$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>21.2$\\pm$12.0</td>\n",
       "      <td>48.9$\\pm$6.0</td>\n",
       "      <td>61.9$\\pm$13.0</td>\n",
       "      <td>86.7$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ood-using-airline</th>\n",
       "      <th>True</th>\n",
       "      <td>20.5$\\pm$19.0</td>\n",
       "      <td>53.8$\\pm$9.0</td>\n",
       "      <td>65.1$\\pm$12.0</td>\n",
       "      <td>87.4$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>30.4$\\pm$17.0</td>\n",
       "      <td>61.6$\\pm$8.0</td>\n",
       "      <td>66.7$\\pm$8.0</td>\n",
       "      <td>88.5$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">airline</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">GPT2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">nondp</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">standard</th>\n",
       "      <th>True</th>\n",
       "      <td>89.6$\\pm$5.0</td>\n",
       "      <td>95.9$\\pm$3.0</td>\n",
       "      <td>91.4$\\pm$4.0</td>\n",
       "      <td>90.8$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>76.5$\\pm$24.0</td>\n",
       "      <td>91.3$\\pm$7.0</td>\n",
       "      <td>84.0$\\pm$10.0</td>\n",
       "      <td>93.5$\\pm$3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">standard</th>\n",
       "      <th>True</th>\n",
       "      <td>43.0$\\pm$28.0</td>\n",
       "      <td>68.5$\\pm$13.0</td>\n",
       "      <td>64.1$\\pm$10.0</td>\n",
       "      <td>93.4$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>60.5$\\pm$7.0</td>\n",
       "      <td>65.3$\\pm$9.0</td>\n",
       "      <td>62.4$\\pm$7.0</td>\n",
       "      <td>90.3$\\pm$3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uniform</th>\n",
       "      <th>True</th>\n",
       "      <td>48.8$\\pm$11.0</td>\n",
       "      <td>57.5$\\pm$7.0</td>\n",
       "      <td>55.2$\\pm$5.0</td>\n",
       "      <td>93.4$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>68.5$\\pm$9.0</td>\n",
       "      <td>77.8$\\pm$10.0</td>\n",
       "      <td>72.1$\\pm$7.0</td>\n",
       "      <td>90.7$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ood-using-adult</th>\n",
       "      <th>True</th>\n",
       "      <td>55.5$\\pm$15.0</td>\n",
       "      <td>69.8$\\pm$7.0</td>\n",
       "      <td>65.9$\\pm$7.0</td>\n",
       "      <td>92.5$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>55.2$\\pm$18.0</td>\n",
       "      <td>62.5$\\pm$19.0</td>\n",
       "      <td>60.0$\\pm$16.0</td>\n",
       "      <td>92.5$\\pm$1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "merged_metric_name2                             efficacy_f1   efficacy_auc  \\\n",
       "dataset llm  eps   approach          shuffle                                 \n",
       "adult   GPT2 nondp standard          True      68.9$\\pm$0.0   90.7$\\pm$0.0   \n",
       "                                     False     69.0$\\pm$1.0   90.7$\\pm$0.0   \n",
       "             1     standard          True     19.5$\\pm$20.0  54.2$\\pm$12.0   \n",
       "                                     False    27.8$\\pm$15.0   58.5$\\pm$7.0   \n",
       "                   uniform           True     19.7$\\pm$13.0   48.0$\\pm$8.0   \n",
       "                                     False    21.2$\\pm$12.0   48.9$\\pm$6.0   \n",
       "                   ood-using-airline True     20.5$\\pm$19.0   53.8$\\pm$9.0   \n",
       "                                     False    30.4$\\pm$17.0   61.6$\\pm$8.0   \n",
       "airline GPT2 nondp standard          True      89.6$\\pm$5.0   95.9$\\pm$3.0   \n",
       "                                     False    76.5$\\pm$24.0   91.3$\\pm$7.0   \n",
       "             1     standard          True     43.0$\\pm$28.0  68.5$\\pm$13.0   \n",
       "                                     False     60.5$\\pm$7.0   65.3$\\pm$9.0   \n",
       "                   uniform           True     48.8$\\pm$11.0   57.5$\\pm$7.0   \n",
       "                                     False     68.5$\\pm$9.0  77.8$\\pm$10.0   \n",
       "                   ood-using-adult   True     55.5$\\pm$15.0   69.8$\\pm$7.0   \n",
       "                                     False    55.2$\\pm$18.0  62.5$\\pm$19.0   \n",
       "\n",
       "merged_metric_name2                          efficacy_accuracy histogram_mean  \n",
       "dataset llm  eps   approach          shuffle                                   \n",
       "adult   GPT2 nondp standard          True         83.7$\\pm$2.0   90.7$\\pm$1.0  \n",
       "                                     False        83.3$\\pm$2.0   90.2$\\pm$0.0  \n",
       "             1     standard          True        64.0$\\pm$13.0   87.7$\\pm$1.0  \n",
       "                                     False        65.2$\\pm$9.0   85.7$\\pm$2.0  \n",
       "                   uniform           True        61.9$\\pm$13.0   87.6$\\pm$1.0  \n",
       "                                     False       61.9$\\pm$13.0   86.7$\\pm$1.0  \n",
       "                   ood-using-airline True        65.1$\\pm$12.0   87.4$\\pm$1.0  \n",
       "                                     False        66.7$\\pm$8.0   88.5$\\pm$1.0  \n",
       "airline GPT2 nondp standard          True         91.4$\\pm$4.0   90.8$\\pm$1.0  \n",
       "                                     False       84.0$\\pm$10.0   93.5$\\pm$3.0  \n",
       "             1     standard          True        64.1$\\pm$10.0   93.4$\\pm$1.0  \n",
       "                                     False        62.4$\\pm$7.0   90.3$\\pm$3.0  \n",
       "                   uniform           True         55.2$\\pm$5.0   93.4$\\pm$1.0  \n",
       "                                     False        72.1$\\pm$7.0   90.7$\\pm$1.0  \n",
       "                   ood-using-adult   True         65.9$\\pm$7.0   92.5$\\pm$1.0  \n",
       "                                     False       60.0$\\pm$16.0   92.5$\\pm$1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps=1\n",
    "\n",
    "query1=f\"llm=='GPT2'and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'standard' and impute=='False' and eps=={eps} and wl == '-1'\"\n",
    "query2=f\"llm=='GPT2'and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'standard' and shuffle == 'True' and impute=='True' and eps=={eps} and wl == '-1'\"\n",
    "query3=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and shuffle == 'True' and impute=='False' and eps=='nondp'\"\n",
    "query4=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and shuffle == 'False' and impute=='False' and eps=='nondp'\"\n",
    "query5=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'uniform' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '0.65'\"\n",
    "query6=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'uniform' and shuffle == 'True' and impute=='True' and eps=={eps} and wl == '0.65'\"\n",
    "query7=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'ood-using-adult' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '0.65'\"\n",
    "query8=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'ood-using-adult' and shuffle == 'True' and impute=='True' and eps=={eps} and wl == '0.65'\"\n",
    "query9=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'ood-using-airline' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '0.65'\"\n",
    "query10=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'ood-using-airline' and shuffle == 'True' and impute=='True' and eps=={eps} and wl == '0.65'\"\n",
    "\n",
    "index=[\"dataset\", \"llm\", \"finetune_type\", \"folder_name\", \"bs\", \"train_epoch\", \"chkt_epoch\",\"eps\", \"clip\",'fake_size', \"LR\", \"shuffle\", \"impute\", \"wl\", \"approach\"]\n",
    "df_tmp=df.query(f\"{query1} or {query2} or {query3} or {query4} or {query5} or {query6} or {query7} or {query8} or {query9} or {query10}\")\n",
    "df_tmp=df_tmp[df_tmp['exp'] != 'baselines_adult']\n",
    "df_tmp=df_tmp[df_tmp['exp'] != 'baseline-test_airline']\n",
    "df_tmp = df_tmp[df_tmp.fake_path.apply(lambda x: 'baselines' not in x)]\n",
    "df_tmp['score']=df_tmp.apply(lambda x: x['score'] * 100 if x['metric'] == 'correlation_accuracy' or x['metric'] == 'pairwise_similarity' else x['score'], axis=1)\n",
    "\n",
    "columns=[\"merged_metric_name2\"]\n",
    "tabular_metrics=['efficacy_f1', 'efficacy_auc', 'efficacy_accuracy', 'histogram_mean']\n",
    "# assert len(df_tmp.fake_path.unique()) == (6*2*4) + (5*1*4)\n",
    "\n",
    "ROUND=1\n",
    "df_tmpp = df_tmp.groupby(index+columns).agg(lambda x:\"$\\pm$\".join([str(x.mean().round(ROUND)), str(x.std().round(ROUND-1))]))[[\"score\"]].reset_index().pivot(columns=columns, index=index, values=\"score\").fillna(\"-\")\n",
    "df_tmpp=df_tmpp.reset_index().set_index(['dataset', 'llm', 'eps', 'approach', 'shuffle'])[tabular_metrics].loc[['adult', 'airline'], :, ['nondp', 1], ['standard', 'uniform', 'ood-using-adult', 'ood-using-airline'], ['True', 'False']]\n",
    "\n",
    "df_tmpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"./results/perp_metrics_synth_data_paths_29.09.24.csv\")\n",
    "df2[\"fake_path\"]=df2.name\n",
    "df2.fake_path = df2.fake_path.apply(lambda x: x.replace(\"/workspace\", \"/home/c01teaf/CISPA-az6/llm_tg-2024/llm-tg\"))\n",
    "df2[[\"dataset\", \"setting\", \"llm\", \"finetune_type\"]] = df2.apply(lambda x: get_dslf(x), axis=1, result_type=\"expand\")\n",
    "df2[\"unique_name\"] = df2.apply(lambda x: \"_\".join(x['fake_path'].split(\"/\")[1:-2]),axis=1)\n",
    "\n",
    "df2['bs']=df2.fake_path.apply(lambda x: get_bs(x))\n",
    "df2['exp']=df2.fake_path.apply(lambda x: get_exp(x))\n",
    "df2['folder_name']=df2.fake_path.apply(lambda x: get_folder_name(x))\n",
    "df2['train_epoch']=df2.fake_path.apply(lambda x: get_train_ep(x))\n",
    "\n",
    "df2['chkt_epoch'] = df2.fake_path.apply(lambda x: get_epoch(x))\n",
    "df2['eps'] = df2.fake_path.apply(lambda x: get_eps(x))\n",
    "df2['clip']=df2.fake_path.apply(lambda x: get_clip(x))\n",
    "df2=df2.fillna(\"None\")\n",
    "\n",
    "df2['LR']=df2.exp.apply(lambda x: x.split(\"-\")[0].strip(\"LR\") if \"LR\" in x else -1)\n",
    "df2['shuffle']=df2.exp.apply(lambda x: x.split(\"_\")[3].split(\"-\")[-1] if \"shuffle\" in x else \"-1\")\n",
    "df2['impute']=df2.folder_name.apply(lambda x: x.split(\"_\")[-1].split(\"-\")[-1] if \"impute\" in x else -1)\n",
    "df2['wl']=df2.exp.apply(lambda x: x.split(\"_\")[-1].strip(\"wl\") if \"wl\" in x else \"-1\")\n",
    "index2=index+[\"LR\", \"shuffle\", \"impute\",\"wl\"]\n",
    "\n",
    "def f(x):\n",
    "    if \"ood\" in x:\n",
    "        return \"OOD\"\n",
    "    elif \"uniform\" in x:\n",
    "        return \"uniform\"\n",
    "    elif \"Standard\" in x:\n",
    "        return \"standard\"\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "df2['approach']=df2.exp.apply(lambda x: f(x))\n",
    "index2=index2+[\"approach\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/cs_w84312s1cxj7105940jzm0000gn/T/ipykernel_56685/1660854799.py:19: FutureWarning: Dropping invalid columns in DataFrameGroupBy.agg is deprecated. In a future version, a TypeError will be raised. Before calling .agg, select only columns which should be valid for the function.\n",
      "  df_tmpp=df_tmp.groupby(index2).agg(lambda x:\"$\\pm$\".join([str(x.mean().round(ROUND2)), str(x.std().round(ROUND-1))]))[columns2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value perp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>llm</th>\n",
       "      <th>eps</th>\n",
       "      <th>approach</th>\n",
       "      <th>shuffle</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">adult</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">GPT2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">nondp</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">standard</th>\n",
       "      <th>True</th>\n",
       "      <td>2.398$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2.482$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">standard</th>\n",
       "      <th>True</th>\n",
       "      <td>3.514$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>3.216$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uniform</th>\n",
       "      <th>True</th>\n",
       "      <td>2.973$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2.887$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">OOD</th>\n",
       "      <th>True</th>\n",
       "      <td>3.269$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>3.058$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">airline</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">GPT2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">nondp</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">standard</th>\n",
       "      <th>True</th>\n",
       "      <td>2.865$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2.901$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">standard</th>\n",
       "      <th>True</th>\n",
       "      <td>4.297$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>3.798$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uniform</th>\n",
       "      <th>True</th>\n",
       "      <td>3.932$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>3.633$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">OOD</th>\n",
       "      <th>True</th>\n",
       "      <td>3.964$\\pm$0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>3.74$\\pm$0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        value perp\n",
       "dataset llm  eps   approach shuffle               \n",
       "adult   GPT2 nondp standard True     2.398$\\pm$0.0\n",
       "                            False    2.482$\\pm$0.0\n",
       "             1     standard True     3.514$\\pm$0.0\n",
       "                            False    3.216$\\pm$0.0\n",
       "                   uniform  True     2.973$\\pm$0.0\n",
       "                            False    2.887$\\pm$0.0\n",
       "                   OOD      True     3.269$\\pm$0.0\n",
       "                            False    3.058$\\pm$0.0\n",
       "airline GPT2 nondp standard True     2.865$\\pm$0.0\n",
       "                            False    2.901$\\pm$0.0\n",
       "             1     standard True     4.297$\\pm$0.0\n",
       "                            False    3.798$\\pm$0.0\n",
       "                   uniform  True     3.932$\\pm$0.0\n",
       "                            False    3.633$\\pm$0.0\n",
       "                   OOD      True     3.964$\\pm$0.0\n",
       "                            False     3.74$\\pm$0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1=f\"dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'standard' and shuffle == 'True' and eps==1 and train_epoch == 10 and wl=='-1'\"\n",
    "query2=f\"dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'standard' and shuffle == 'False' and eps==1 and train_epoch == 10 and wl=='-1'\"\n",
    "query3=f\"dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'uniform' and shuffle == 'False' and eps==1 and train_epoch == 10 and wl=='0.65'\"\n",
    "query4=f\"dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'uniform' and shuffle == 'True' and eps==1 and train_epoch == 10 and wl=='0.65'\"\n",
    "query5=f\"dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'OOD' and shuffle == 'True' and eps==1 and train_epoch == 10 and wl=='0.65'\"\n",
    "query6=f\"dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'OOD' and shuffle == 'False' and eps==1 and train_epoch == 10 and wl=='0.65'\"\n",
    "query7=f\"dataset in ('adult', 'airline') and LR=='0.0005' and shuffle == 'False' and eps=='nondp' and train_epoch == 10 and wl=='-1'\"\n",
    "query8=f\"dataset in ('adult', 'airline') and LR=='0.0005' and shuffle == 'True' and eps=='nondp' and train_epoch == 10 and wl=='-1'\"\n",
    "\n",
    "\n",
    "index2=[\"dataset\", \"llm\", \"finetune_type\", \"folder_name\", \"bs\", \"train_epoch\", \"chkt_epoch\",\"eps\", \"clip\"]\n",
    "\n",
    "index2=index2+[\"LR\", \"shuffle\", \"impute\",\"wl\"]\n",
    "index2=index2+[\"approach\"]\n",
    "\n",
    "df_tmp=df2.query(f\"{query1} or {query2} or {query3} or {query4} or {query5} or {query6} or {query7} or {query8}\")\n",
    "columns2=['value perp']\n",
    "ROUND2=3\n",
    "df_tmpp=df_tmp.groupby(index2).agg(lambda x:\"$\\pm$\".join([str(x.mean().round(ROUND2)), str(x.std().round(ROUND-1))]))[columns2]\n",
    "df_tmpp.reset_index().set_index(['dataset', 'llm', 'eps', 'approach', 'shuffle'])[['value perp']].loc[['adult', 'airline'], :, ['nondp', 1], ['standard', 'uniform', 'OOD'], ['True', 'False']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/cs_w84312s1cxj7105940jzm0000gn/T/ipykernel_56685/615234026.py:24: FutureWarning: Dropping invalid columns in DataFrameGroupBy.agg is deprecated. In a future version, a TypeError will be raised. Before calling .agg, select only columns which should be valid for the function.\n",
      "  df_tmpp = df_tmp.groupby(index+columns).agg(lambda x:\"$\\pm$\".join([str(x.mean().round(ROUND)), str(x.std().round(ROUND-1))]))[[\"score\"]].reset_index().pivot(columns=columns, index=index, values=\"score\").fillna(\"-\")\n",
      "/var/folders/z5/cs_w84312s1cxj7105940jzm0000gn/T/ipykernel_56685/615234026.py:25: FutureWarning: The behavior of indexing on a MultiIndex with a nested sequence of labels is deprecated and will change in a future version. `series.loc[label, sequence]` will raise if any members of 'sequence' or not present in the index's second level. To retain the old behavior, use `series.index.isin(sequence, level=1)`\n",
      "  df_tmpp=df_tmpp.reset_index().set_index(['dataset', 'llm', 'eps', 'approach', 'wl'])[tabular_metrics].loc[['adult', 'airline'], :, ['nondp', 1], ['standard', 'uniform', 'ood-using-adult', 'ood-using-airline'], ['-1', '0.65']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>merged_metric_name2</th>\n",
       "      <th>efficacy_f1</th>\n",
       "      <th>efficacy_auc</th>\n",
       "      <th>efficacy_accuracy</th>\n",
       "      <th>histogram_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>llm</th>\n",
       "      <th>eps</th>\n",
       "      <th>approach</th>\n",
       "      <th>wl</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">adult</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">GPT2</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">standard</th>\n",
       "      <th>-1</th>\n",
       "      <td>27.8$\\pm$15.0</td>\n",
       "      <td>58.5$\\pm$7.0</td>\n",
       "      <td>65.2$\\pm$9.0</td>\n",
       "      <td>85.7$\\pm$2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>28.9$\\pm$17.0</td>\n",
       "      <td>60.9$\\pm$8.0</td>\n",
       "      <td>66.8$\\pm$8.0</td>\n",
       "      <td>87.4$\\pm$2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uniform</th>\n",
       "      <th>-1</th>\n",
       "      <td>20.8$\\pm$14.0</td>\n",
       "      <td>49.7$\\pm$7.0</td>\n",
       "      <td>63.0$\\pm$12.0</td>\n",
       "      <td>87.3$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>21.2$\\pm$12.0</td>\n",
       "      <td>48.9$\\pm$6.0</td>\n",
       "      <td>61.9$\\pm$13.0</td>\n",
       "      <td>86.7$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ood-using-airline</th>\n",
       "      <th>-1</th>\n",
       "      <td>30.3$\\pm$15.0</td>\n",
       "      <td>60.4$\\pm$7.0</td>\n",
       "      <td>65.8$\\pm$9.0</td>\n",
       "      <td>87.3$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>30.4$\\pm$17.0</td>\n",
       "      <td>61.6$\\pm$8.0</td>\n",
       "      <td>66.7$\\pm$8.0</td>\n",
       "      <td>88.5$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">airline</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">GPT2</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">standard</th>\n",
       "      <th>-1</th>\n",
       "      <td>60.5$\\pm$7.0</td>\n",
       "      <td>65.3$\\pm$9.0</td>\n",
       "      <td>62.4$\\pm$7.0</td>\n",
       "      <td>90.3$\\pm$3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>59.9$\\pm$7.0</td>\n",
       "      <td>65.7$\\pm$9.0</td>\n",
       "      <td>62.9$\\pm$7.0</td>\n",
       "      <td>91.6$\\pm$4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uniform</th>\n",
       "      <th>-1</th>\n",
       "      <td>65.0$\\pm$10.0</td>\n",
       "      <td>74.5$\\pm$9.0</td>\n",
       "      <td>69.3$\\pm$6.0</td>\n",
       "      <td>91.1$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>68.5$\\pm$9.0</td>\n",
       "      <td>77.8$\\pm$10.0</td>\n",
       "      <td>72.1$\\pm$7.0</td>\n",
       "      <td>90.7$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ood-using-adult</th>\n",
       "      <th>-1</th>\n",
       "      <td>48.8$\\pm$17.0</td>\n",
       "      <td>55.6$\\pm$19.0</td>\n",
       "      <td>54.4$\\pm$15.0</td>\n",
       "      <td>92.4$\\pm$1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>55.2$\\pm$18.0</td>\n",
       "      <td>62.5$\\pm$19.0</td>\n",
       "      <td>60.0$\\pm$16.0</td>\n",
       "      <td>92.5$\\pm$1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "merged_metric_name2                        efficacy_f1   efficacy_auc  \\\n",
       "dataset llm  eps approach          wl                                   \n",
       "adult   GPT2 1   standard          -1    27.8$\\pm$15.0   58.5$\\pm$7.0   \n",
       "                                   0.65  28.9$\\pm$17.0   60.9$\\pm$8.0   \n",
       "                 uniform           -1    20.8$\\pm$14.0   49.7$\\pm$7.0   \n",
       "                                   0.65  21.2$\\pm$12.0   48.9$\\pm$6.0   \n",
       "                 ood-using-airline -1    30.3$\\pm$15.0   60.4$\\pm$7.0   \n",
       "                                   0.65  30.4$\\pm$17.0   61.6$\\pm$8.0   \n",
       "airline GPT2 1   standard          -1     60.5$\\pm$7.0   65.3$\\pm$9.0   \n",
       "                                   0.65   59.9$\\pm$7.0   65.7$\\pm$9.0   \n",
       "                 uniform           -1    65.0$\\pm$10.0   74.5$\\pm$9.0   \n",
       "                                   0.65   68.5$\\pm$9.0  77.8$\\pm$10.0   \n",
       "                 ood-using-adult   -1    48.8$\\pm$17.0  55.6$\\pm$19.0   \n",
       "                                   0.65  55.2$\\pm$18.0  62.5$\\pm$19.0   \n",
       "\n",
       "merged_metric_name2                     efficacy_accuracy histogram_mean  \n",
       "dataset llm  eps approach          wl                                     \n",
       "adult   GPT2 1   standard          -1        65.2$\\pm$9.0   85.7$\\pm$2.0  \n",
       "                                   0.65      66.8$\\pm$8.0   87.4$\\pm$2.0  \n",
       "                 uniform           -1       63.0$\\pm$12.0   87.3$\\pm$1.0  \n",
       "                                   0.65     61.9$\\pm$13.0   86.7$\\pm$1.0  \n",
       "                 ood-using-airline -1        65.8$\\pm$9.0   87.3$\\pm$1.0  \n",
       "                                   0.65      66.7$\\pm$8.0   88.5$\\pm$1.0  \n",
       "airline GPT2 1   standard          -1        62.4$\\pm$7.0   90.3$\\pm$3.0  \n",
       "                                   0.65      62.9$\\pm$7.0   91.6$\\pm$4.0  \n",
       "                 uniform           -1        69.3$\\pm$6.0   91.1$\\pm$1.0  \n",
       "                                   0.65      72.1$\\pm$7.0   90.7$\\pm$1.0  \n",
       "                 ood-using-adult   -1       54.4$\\pm$15.0   92.4$\\pm$1.0  \n",
       "                                   0.65     60.0$\\pm$16.0   92.5$\\pm$1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps=1\n",
    "\n",
    "query1=f\"llm=='GPT2'and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'standard' and impute=='False' and eps=={eps} and wl == '0.65'\"\n",
    "query2=f\"llm=='GPT2'and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'standard' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '-1'\"\n",
    "query3=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'uniform' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '0.65'\"\n",
    "query4=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'uniform' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '-1'\"\n",
    "query5=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'ood-using-adult' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '0.65'\"\n",
    "query6=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'ood-using-adult' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '-1'\"\n",
    "query7=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'ood-using-airline' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '0.65'\"\n",
    "query8=f\"llm=='GPT2' and dataset in ('adult', 'airline') and LR=='0.0005' and approach == 'ood-using-airline' and shuffle == 'False' and impute=='False' and eps=={eps} and wl == '-1'\"\n",
    "\n",
    "index=[\"dataset\", \"llm\", \"finetune_type\", \"folder_name\", \"bs\", \"train_epoch\", \"chkt_epoch\",\"eps\", \"clip\",'fake_size', \"LR\", \"shuffle\", \"impute\", \"wl\", \"approach\"]\n",
    "df_tmp=df.query(f\"{query1} or {query2} or {query3} or {query4} or {query5} or {query6} or {query7} or {query8}\")\n",
    "df_tmp=df_tmp[df_tmp['exp'] != 'baselines_adult']\n",
    "df_tmp=df_tmp[df_tmp['exp'] != 'baseline-test_airline']\n",
    "df_tmp = df_tmp[df_tmp.fake_path.apply(lambda x: 'baselines' not in x)]\n",
    "df_tmp['score']=df_tmp.apply(lambda x: x['score'] * 100 if x['metric'] == 'correlation_accuracy' or x['metric'] == 'pairwise_similarity' else x['score'], axis=1)\n",
    "\n",
    "columns=[\"merged_metric_name2\"]\n",
    "tabular_metrics=['efficacy_f1', 'efficacy_auc', 'efficacy_accuracy', 'histogram_mean']\n",
    "# assert len(df_tmp.fake_path.unique()) == (6*2*4) + (5*1*4)\n",
    "\n",
    "ROUND=1\n",
    "df_tmpp = df_tmp.groupby(index+columns).agg(lambda x:\"$\\pm$\".join([str(x.mean().round(ROUND)), str(x.std().round(ROUND-1))]))[[\"score\"]].reset_index().pivot(columns=columns, index=index, values=\"score\").fillna(\"-\")\n",
    "df_tmpp=df_tmpp.reset_index().set_index(['dataset', 'llm', 'eps', 'approach', 'wl'])[tabular_metrics].loc[['adult', 'airline'], :, ['nondp', 1], ['standard', 'uniform', 'ood-using-adult', 'ood-using-airline'], ['-1', '0.65']]\n",
    "\n",
    "df_tmpp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp2stage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
